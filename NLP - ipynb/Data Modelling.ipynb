{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f49e536",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Prepare the data for modelling, This will include\n",
    "- Converting to lowercase\n",
    "- Removing stopwords\n",
    "- Lemmatization\n",
    "- Stemming\n",
    "- Removing numbers \n",
    "\n",
    "# Question 2\n",
    "Once the data has been cleaned :-\n",
    "- Divide the data intro train and test parts\n",
    "- Convert the training and text text into vectors \n",
    "- Convert the labels intro numbers(encoding)\n",
    "\n",
    "Overall, you should end up with 4 varaibles \n",
    "- Xtrain\n",
    "- Xtest\n",
    "- Ytrain\n",
    "- Ytest\n",
    "\n",
    "You can name these whatever you want, upto you. But i am looking for these 4 variables ready to go for modelling\n",
    "\n",
    "------------\n",
    "\n",
    "![](https://media.tenor.com/d8fG2J6pkAUAAAAC/friends-chandler.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0058752",
   "metadata": {},
   "source": [
    "# Note \n",
    "The file is stored as a ```tsv```.\n",
    "\n",
    "You can load a ```tsv``` file with ```pd.read_csv``` while passing the seperator or ```sep``` argument as ```\\t```.\n",
    "\n",
    "This tells pandas that the file is seperated by tab's instead of comma's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e0aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words(\"english\")\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sn_stemmer = SnowballStemmer(\"english\")\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb89bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Restaurant_Reviews.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f932db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae82f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_function(x):\n",
    "    x = x.lower()\n",
    "    y=nltk.word_tokenize(x)\n",
    "    temp=[]\n",
    "    for i in y:\n",
    "        if i in stopwords.words(\"english\"): \n",
    "             pass\n",
    "        else:\n",
    "             temp.append(i)\n",
    "    stop=' '.join(temp)\n",
    "    \n",
    "    c=nltk.word_tokenize(stop)\n",
    "    temp2=[]\n",
    "    for i in c:\n",
    "        temp2.append(lemmatizer.lemmatize(i))\n",
    "        lem=' '.join(temp2)\n",
    "        \n",
    "    d=nltk.word_tokenize(lem)\n",
    "    temp3 = []\n",
    "    for i in d:\n",
    "        temp3.append((sn_stemmer.stem(i)))\n",
    "        stem=' '.join(temp3)\n",
    "\n",
    "    temp4 = []\n",
    "    for i in stem:\n",
    "        if i.isdigit():\n",
    "            pass\n",
    "        else:\n",
    "            temp4.append(i)\n",
    "        number =''.join(temp4)\n",
    "    return(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecdecdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean Msg'] = df['Review'].apply(new_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cdf7d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean Msg</th>\n",
       "      <th>Clean Msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow ... love place .</td>\n",
       "      <td>wow ... love place .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust good .</td>\n",
       "      <td>crust good .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>tasti textur nasti .</td>\n",
       "      <td>tasti textur nasti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>select menu great price .</td>\n",
       "      <td>select menu great price .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>think food flavor textur lack .</td>\n",
       "      <td>think food flavor textur lack .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>appetit instant gone .</td>\n",
       "      <td>appetit instant gone .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>overal impress would go back .</td>\n",
       "      <td>overal impress would go back .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>whole experi underwhelm , think ll go ninja su...</td>\n",
       "      <td>whole experi underwhelm , think ll go ninja su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>, n't wast enough life , pour salt wound draw ...</td>\n",
       "      <td>, n't wast enough life , pour salt wound draw ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked  \\\n",
       "0                             Wow... Loved this place.      1   \n",
       "1                                   Crust is not good.      0   \n",
       "2            Not tasty and the texture was just nasty.      0   \n",
       "3    Stopped by during the late May bank holiday of...      1   \n",
       "4    The selection on the menu was great and so wer...      1   \n",
       "..                                                 ...    ...   \n",
       "995  I think food should have flavor and texture an...      0   \n",
       "996                           Appetite instantly gone.      0   \n",
       "997  Overall I was not impressed and would not go b...      0   \n",
       "998  The whole experience was underwhelming, and I ...      0   \n",
       "999  Then, as if I hadn't wasted enough of my life ...      0   \n",
       "\n",
       "                                            Clean Msg   \\\n",
       "0                                 wow ... love place .   \n",
       "1                                         crust good .   \n",
       "2                                 tasti textur nasti .   \n",
       "3    stop late may bank holiday rick steve recommen...   \n",
       "4                            select menu great price .   \n",
       "..                                                 ...   \n",
       "995                    think food flavor textur lack .   \n",
       "996                             appetit instant gone .   \n",
       "997                     overal impress would go back .   \n",
       "998  whole experi underwhelm , think ll go ninja su...   \n",
       "999  , n't wast enough life , pour salt wound draw ...   \n",
       "\n",
       "                                             Clean Msg  \n",
       "0                                 wow ... love place .  \n",
       "1                                         crust good .  \n",
       "2                                 tasti textur nasti .  \n",
       "3    stop late may bank holiday rick steve recommen...  \n",
       "4                            select menu great price .  \n",
       "..                                                 ...  \n",
       "995                    think food flavor textur lack .  \n",
       "996                             appetit instant gone .  \n",
       "997                     overal impress would go back .  \n",
       "998  whole experi underwhelm , think ll go ninja su...  \n",
       "999  , n't wast enough life , pour salt wound draw ...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c23219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df['Clean Msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468ee4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df['Liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5571c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "837f1404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90               summari , larg disappoint dine experi .\n",
       " 675                       fantast neighborhood gem ! ! !\n",
       " 130                      place way overpr mediocr food .\n",
       " 329            mom got home immedi got sick bite salad .\n",
       " 426      serious good pizza 'm expert/connisseur topic .\n",
       "                              ...                        \n",
       " 607                                          want leav .\n",
       " 623    drive thru mean want wait around half hour foo...\n",
       " 535              excel new restaur experienc frenchman .\n",
       " 99                   side , cafe serf realli good food .\n",
       " 549    boyfriend came first time recent trip vega cou...\n",
       " Name: Clean Msg, Length: 800, dtype: object,\n",
       " 273    stop place madison ironman , friend , kind sta...\n",
       " 841                                food came good pace .\n",
       " 198                                       friend staff .\n",
       " 603              good valu , great food , great servic .\n",
       " 661                            conveni , sinc stay mgm !\n",
       "                              ...                        \n",
       " 304                                 good service-check !\n",
       " 46                            's bad food damn generic .\n",
       " 999    , n't wast enough life , pour salt wound draw ...\n",
       " 920             needl say , wo n't go back anytim soon .\n",
       " 649                         wo n't go back anytim soon !\n",
       " Name: Clean Msg, Length: 200, dtype: object,\n",
       " 90     0\n",
       " 675    1\n",
       " 130    0\n",
       " 329    0\n",
       " 426    1\n",
       "       ..\n",
       " 607    0\n",
       " 623    0\n",
       " 535    1\n",
       " 99     1\n",
       " 549    1\n",
       " Name: Liked, Length: 800, dtype: int64,\n",
       " 273    1\n",
       " 841    1\n",
       " 198    1\n",
       " 603    1\n",
       " 661    1\n",
       "       ..\n",
       " 304    1\n",
       " 46     0\n",
       " 999    0\n",
       " 920    0\n",
       " 649    0\n",
       " Name: Liked, Length: 200, dtype: int64]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(df_x, df_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5cb05ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703                      server nice attent serv staff .\n",
       "311            order toast english muffin came untoast .\n",
       "722                 food great alway , compliment chef .\n",
       "629    staff alway super friend help , especi cool br...\n",
       "0                                   wow ... love place .\n",
       "                             ...                        \n",
       "106    food delici , bartend attent person got great ...\n",
       "270                          veggitarian platter world !\n",
       "860        place pretti good , nice littl vibe restaur .\n",
       "435          huge awkward .lb piec cow /ths gristl fat .\n",
       "102                      best buffet town , price beat .\n",
       "Name: Clean Msg, Length: 670, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4be27f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521                                        n't gone go !\n",
       "737    tri airport experi tasti food speedi , friend ...\n",
       "740                  restaur clean famili restaur feel .\n",
       "660    person love hummus , pita , baklava , falafel ...\n",
       "411                      come hungri , leav happi stuf !\n",
       "                             ...                        \n",
       "506                            overal n't impress noca .\n",
       "342            veget fresh sauc feel like authent thai .\n",
       "485     n't small famili restaur , fine dine establish .\n",
       "711                                              thing .\n",
       "133                                         manag rude .\n",
       "Name: Clean Msg, Length: 330, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170e8a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703    1\n",
       "311    0\n",
       "722    1\n",
       "629    1\n",
       "0      1\n",
       "      ..\n",
       "106    1\n",
       "270    1\n",
       "860    1\n",
       "435    0\n",
       "102    1\n",
       "Name: Liked, Length: 670, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01abc7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521    1\n",
       "737    1\n",
       "740    1\n",
       "660    1\n",
       "411    1\n",
       "      ..\n",
       "506    0\n",
       "342    1\n",
       "485    1\n",
       "711    0\n",
       "133    0\n",
       "Name: Liked, Length: 330, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a928b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvector = CountVectorizer()\n",
    "countvector.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5d2879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<670x1255 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3693 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1464fefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bill', 'bird', 'biscuit', 'bisqu', 'bit', 'bitch', 'bite',\n",
       "       'black', 'blah', 'blame', 'bland', 'blanket', 'bloodi', 'blown',\n",
       "       'blue', 'boba', 'bode', 'bone', 'book', 'boot', 'bore', 'bother',\n",
       "       'bottom', 'bouchon', 'bought', 'bowl', 'boy', 'boyfriend', 'bread',\n",
       "       'break', 'breakfast', 'breez', 'brick', 'bring', 'brother',\n",
       "       'brought', 'brownish', 'brunch', 'bruschetta', 'buck', 'buffet',\n",
       "       'build', 'buldogi', 'bunch', 'burger', 'burritto', 'bus', 'busi',\n",
       "       'bussel', 'butter', 'bye', 'ca', 'caballero', 'caesar', 'cafe',\n",
       "       'café', 'calamari', 'call', 'calligraphi', 'came', 'camelback',\n",
       "       'cant', 'cape', 'caper', 'car', 'care', 'cart', 'cartel', 'case',\n",
       "       'cash', 'cashew', 'cashier', 'casino', 'caterpillar', 'caught',\n",
       "       'caus', 'certain', 'chai', 'chain', 'chang', 'char', 'charcoal',\n",
       "       'charm', 'cheap', 'check', 'cheek', 'chees', 'cheeseburg',\n",
       "       'cheesecurd', 'chef', 'chewi', 'chicken', 'chines', 'chip',\n",
       "       'chipolt', 'chocol', 'choos', 'chou', 'chow', 'christma'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvector.get_feature_names_out()[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7020e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = countvector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89bcf039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<670x1255 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3693 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edc59204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<330x1255 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1390 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27817f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = countvector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30ae3a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daa6b5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3670807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3a2f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5518aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac746e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb11e1",
   "metadata": {},
   "source": [
    "# Now we have 4 variables ready to go for modelling\n",
    "- x_train_vec\n",
    "- x_test_vec\n",
    "- y_train_encoded\n",
    "- y_test_encoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
